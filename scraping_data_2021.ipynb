{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_data_open_and_games(year, competition, scores=False):\n",
    "    base_url = \"https://c3po.crossfit.com/api/leaderboards/v2/competitions\"\n",
    "    data_list = []\n",
    "    genders = [1, 2]\n",
    "\n",
    "    # Iterate over each gender\n",
    "    for gender in genders:\n",
    "        # Create the initial API URL to fetch the data for the first page\n",
    "        url = f\"{base_url}/{competition}/{year}/leaderboards?division={gender}&page=1\"\n",
    "        try:\n",
    "            # Fetch the response for the first page\n",
    "            response = requests.get(url).json()\n",
    "            # Extract the total number of pages from the response\n",
    "            total_pages = response['pagination']['totalPages']\n",
    "            # Iterate over each page\n",
    "            for page in range(1, total_pages + 1):\n",
    "                # Create the API URL for each page\n",
    "                url = f\"{base_url}/{competition}/{year}/leaderboards?division={gender}&page={page}\"\n",
    "                try:\n",
    "                    # Fetch the response for the current page\n",
    "                    response = requests.get(url).json()\n",
    "                    # Extract the data for each row in the leaderboardRows\n",
    "                    for row in response['leaderboardRows']:\n",
    "                        # Append entrant data for the first query\n",
    "                        if not scores:\n",
    "                            row_data = row['entrant'].copy()\n",
    "                            row_data['overallRank'] = row['overallRank']\n",
    "                            row_data['overallScore'] = row['overallScore']\n",
    "                            # Append the row data to the data_list\n",
    "                            data_list.append(row_data)\n",
    "                        # Append score data for the second query\n",
    "                        else:\n",
    "                            total_ordinals = pd.DataFrame(row['scores'] for row in response['leaderboardRows']).shape[1]\n",
    "                            for ordinal in range(0, total_ordinals):\n",
    "                                score_data = row['scores'][ordinal].copy()\n",
    "                                score_data['competitorId'] = row['entrant']['competitorId']\n",
    "                                # Append the score data to the data_list\n",
    "                                data_list.append(score_data)\n",
    "                except Exception as e:\n",
    "                    # Handle any errors that occur during the API request for a specific page\n",
    "                    print(f\"Error occurred while fetching data for gender={gender}, page={page}: {e}\")\n",
    "        except Exception as e:\n",
    "            # Handle any errors that occur during the API request for fetching total_pages\n",
    "            print(f\"Error occurred while fetching total_pages for gender={gender}: {e}\")\n",
    "\n",
    "    # Create a DataFrame from the collected data_list\n",
    "    df = pd.DataFrame(data_list)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2021"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Open"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Athletes information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1 - 2021 Open Not Scores\n",
    "df_2021_open_not_scores = scraping_data_open_and_games('2021', 'open')\n",
    "\n",
    "df_2021_open_not_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorId</th>\n",
       "      <th>competitorName</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>status</th>\n",
       "      <th>postCompStatus</th>\n",
       "      <th>gender</th>\n",
       "      <th>profilePicS3key</th>\n",
       "      <th>countryOfOriginCode</th>\n",
       "      <th>countryOfOriginName</th>\n",
       "      <th>...</th>\n",
       "      <th>regionName</th>\n",
       "      <th>divisionId</th>\n",
       "      <th>affiliateId</th>\n",
       "      <th>affiliateName</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>teamCaptain</th>\n",
       "      <th>overallRank</th>\n",
       "      <th>overallScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>469656</td>\n",
       "      <td>Jeffrey Adler</td>\n",
       "      <td>Jeffrey</td>\n",
       "      <td>Adler</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>e480e-P469656_1-184.jpg</td>\n",
       "      <td>CA</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>18059</td>\n",
       "      <td>CrossFit Wonderland</td>\n",
       "      <td>27</td>\n",
       "      <td>69 in</td>\n",
       "      <td>197 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34796</td>\n",
       "      <td>Scott Panchik</td>\n",
       "      <td>Scott</td>\n",
       "      <td>Panchik</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>e23e0-P34796_8-184.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>7991</td>\n",
       "      <td>CrossFit Mentality</td>\n",
       "      <td>33</td>\n",
       "      <td>69 in</td>\n",
       "      <td>187 lb</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105875</td>\n",
       "      <td>Travis Mead</td>\n",
       "      <td>Travis</td>\n",
       "      <td>Mead</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>7ebb9-P105875_6-184.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>9155</td>\n",
       "      <td>Iron Valley CrossFit</td>\n",
       "      <td>34</td>\n",
       "      <td>73 in</td>\n",
       "      <td>205 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>310970</td>\n",
       "      <td>Saxon Panchik</td>\n",
       "      <td>Saxon</td>\n",
       "      <td>Panchik</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>00087-P310970_11-184.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>22505</td>\n",
       "      <td>CrossFit Cliffside</td>\n",
       "      <td>25</td>\n",
       "      <td>69 in</td>\n",
       "      <td>180 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11435</td>\n",
       "      <td>Richard Froning Jr.</td>\n",
       "      <td>Richard</td>\n",
       "      <td>Froning Jr.</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>e61ee-P11435_12-184.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>3220</td>\n",
       "      <td>CrossFit Mayhem</td>\n",
       "      <td>33</td>\n",
       "      <td>69 in</td>\n",
       "      <td>194 lb</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246100</th>\n",
       "      <td>170162</td>\n",
       "      <td>Sarah Lucas</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Lucas</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>73b48-P170162_1-184.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>38</td>\n",
       "      <td>66 in</td>\n",
       "      <td>142 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>108565</td>\n",
       "      <td>374151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246101</th>\n",
       "      <td>1166348</td>\n",
       "      <td>Karen Thomson</td>\n",
       "      <td>Karen</td>\n",
       "      <td>Thomson</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>women-square.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>13</td>\n",
       "      <td>18077</td>\n",
       "      <td>CrossFit SFP</td>\n",
       "      <td>40</td>\n",
       "      <td>70 in</td>\n",
       "      <td>145 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>108565</td>\n",
       "      <td>374151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246102</th>\n",
       "      <td>27733</td>\n",
       "      <td>Natascha Heller</td>\n",
       "      <td>Natascha</td>\n",
       "      <td>Heller</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>e57e0-P27733_2-184.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>6</td>\n",
       "      <td>12853</td>\n",
       "      <td>UnScared CrossFit</td>\n",
       "      <td>50</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>108565</td>\n",
       "      <td>374151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246103</th>\n",
       "      <td>1953600</td>\n",
       "      <td>Lindsey Miller</td>\n",
       "      <td>Lindsey</td>\n",
       "      <td>Miller</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>women-square.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>27</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>108565</td>\n",
       "      <td>374151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246104</th>\n",
       "      <td>1945160</td>\n",
       "      <td>Christa Lane</td>\n",
       "      <td>Christa</td>\n",
       "      <td>Lane</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>women-square.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>19</td>\n",
       "      <td>14769</td>\n",
       "      <td>CrossFit Unsung</td>\n",
       "      <td>36</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>108565</td>\n",
       "      <td>374151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246105 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       competitorId       competitorName firstName     lastName status  \\\n",
       "0            469656        Jeffrey Adler   Jeffrey        Adler    ACT   \n",
       "1             34796        Scott Panchik     Scott      Panchik    ACT   \n",
       "2            105875          Travis Mead    Travis         Mead    ACT   \n",
       "3            310970        Saxon Panchik     Saxon      Panchik    ACT   \n",
       "4             11435  Richard Froning Jr.   Richard  Froning Jr.    ACT   \n",
       "...             ...                  ...       ...          ...    ...   \n",
       "246100       170162          Sarah Lucas     Sarah        Lucas    ACT   \n",
       "246101      1166348        Karen Thomson     Karen      Thomson    ACT   \n",
       "246102        27733      Natascha Heller  Natascha       Heller    ACT   \n",
       "246103      1953600       Lindsey Miller   Lindsey       Miller    ACT   \n",
       "246104      1945160         Christa Lane   Christa         Lane    ACT   \n",
       "\n",
       "       postCompStatus gender           profilePicS3key countryOfOriginCode  \\\n",
       "0                          M   e480e-P469656_1-184.jpg                  CA   \n",
       "1                          M    e23e0-P34796_8-184.jpg                  US   \n",
       "2                          M   7ebb9-P105875_6-184.jpg                  US   \n",
       "3                          M  00087-P310970_11-184.jpg                  US   \n",
       "4                          M   e61ee-P11435_12-184.jpg                  US   \n",
       "...               ...    ...                       ...                 ...   \n",
       "246100                     F   73b48-P170162_1-184.jpg                  US   \n",
       "246101                     F          women-square.jpg                  US   \n",
       "246102                     F    e57e0-P27733_2-184.jpg                  US   \n",
       "246103                     F          women-square.jpg                  US   \n",
       "246104                     F          women-square.jpg                  US   \n",
       "\n",
       "       countryOfOriginName  ...     regionName divisionId affiliateId  \\\n",
       "0                   Canada  ...  North America          1       18059   \n",
       "1            United States  ...  North America          1        7991   \n",
       "2            United States  ...  North America          1        9155   \n",
       "3            United States  ...  North America          1       22505   \n",
       "4            United States  ...  North America          1        3220   \n",
       "...                    ...  ...            ...        ...         ...   \n",
       "246100       United States  ...  North America         19        None   \n",
       "246101       United States  ...  North America         13       18077   \n",
       "246102       United States  ...  North America          6       12853   \n",
       "246103       United States  ...  North America          2        None   \n",
       "246104       United States  ...  North America         19       14769   \n",
       "\n",
       "               affiliateName age height  weight teamCaptain overallRank  \\\n",
       "0        CrossFit Wonderland  27  69 in  197 lb           0           1   \n",
       "1         CrossFit Mentality  33  69 in  187 lb           1           2   \n",
       "2       Iron Valley CrossFit  34  73 in  205 lb           0           3   \n",
       "3         CrossFit Cliffside  25  69 in  180 lb           0           4   \n",
       "4            CrossFit Mayhem  33  69 in  194 lb           1           5   \n",
       "...                      ...  ..    ...     ...         ...         ...   \n",
       "246100                        38  66 in  142 lb           0      108565   \n",
       "246101          CrossFit SFP  40  70 in  145 lb           0      108565   \n",
       "246102     UnScared CrossFit  50                          0      108565   \n",
       "246103                        27                          0      108565   \n",
       "246104       CrossFit Unsung  36                          0      108565   \n",
       "\n",
       "       overallScore  \n",
       "0               101  \n",
       "1               141  \n",
       "2               165  \n",
       "3               217  \n",
       "4               254  \n",
       "...             ...  \n",
       "246100       374151  \n",
       "246101       374151  \n",
       "246102       374151  \n",
       "246103       374151  \n",
       "246104       374151  \n",
       "\n",
       "[246105 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query 1 - 2021 Open Not Scores\n",
    "df_2021_open_not_scores = scraping_data_open_and_games('2021', 'open')\n",
    "\n",
    "df_2021_open_not_scores\n",
    "\n",
    "# base_url = \"https://c3po.crossfit.com/api/leaderboards/v2/competitions/open/2021/leaderboards\"\n",
    "\n",
    "# data_list = []\n",
    "# genders = [1, 2]\n",
    "\n",
    "# # Iterate over each gender\n",
    "# for gender in genders:\n",
    "#     # Create the initial API URL to fetch the data for the first page\n",
    "#     url = f\"{base_url}?division={gender}&page=1\"\n",
    "#     try:\n",
    "#         # Fetch the response for the first page\n",
    "#         response = requests.get(url).json()\n",
    "#         # Extract the total number of pages from the response\n",
    "#         total_pages = response['pagination']['totalPages']\n",
    "#         # Iterate over each page\n",
    "#         for page in range(1, total_pages + 1):\n",
    "#             # Create the API URL for each page\n",
    "#             url = f\"{base_url}?division={gender}&page={page}\"\n",
    "#             try:\n",
    "#                 # Fetch the response for the current page\n",
    "#                 response = requests.get(url).json()\n",
    "#                 # Extract the data for each row in the leaderboardRows\n",
    "#                 for row in response['leaderboardRows']:\n",
    "#                     # Copy the entrant data and add additional fields for overallRank and overallScore\n",
    "#                     row_data = row['entrant'].copy()\n",
    "#                     row_data['overallRank'] = row['overallRank']\n",
    "#                     row_data['overallScore'] = row['overallScore']\n",
    "#                     # Append the row data to the data_list\n",
    "#                     data_list.append(row_data)\n",
    "#             except Exception as e:\n",
    "#                 # Handle any errors that occur during the API request for a specific page\n",
    "#                 print(f\"Error occurred while fetching data for gender={gender}, page={page}: {e}\")\n",
    "#     except Exception as e:\n",
    "#         # Handle any errors that occur during the API request for fetching total_pages\n",
    "#         print(f\"Error occurred while fetching total_pages for gender={gender}: {e}\")\n",
    "\n",
    "# # Create a DataFrame from the collected data_list\n",
    "# df = pd.DataFrame(data_list)\n",
    "\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Athletes scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2 - 2021 Open Scores\n",
    "df_2021_open_scores = scraping_data_open_and_games('2021', 'open', scores=True)\n",
    "\n",
    "df_2021_open_scores\n",
    "\n",
    "# base_url = \"https://c3po.crossfit.com/api/leaderboards/v2/competitions/open/2021/leaderboards\"\n",
    "\n",
    "# data_list = []\n",
    "# genders = [1, 2]\n",
    "\n",
    "# # Iterate over each gender\n",
    "# for gender in genders:\n",
    "#     # Create the initial API URL to fetch the data for the first page\n",
    "#     url = f\"{base_url}?division={gender}&page=1\"\n",
    "#     try:\n",
    "#         # Fetch the response for the first page\n",
    "#         response = requests.get(url).json()\n",
    "#         # Extract the total number of pages from the response\n",
    "#         total_pages = response['pagination']['totalPages']\n",
    "#         # Iterate over each page\n",
    "#         for page in range(1, total_pages + 1):\n",
    "#             # Create the API URL for each page\n",
    "#             url = f\"{base_url}?division={gender}&page={page}\"\n",
    "#             try:\n",
    "#                 # Fetch the response for the current page\n",
    "#                 response = requests.get(url).json()\n",
    "#                 # Extract the data for each row in the leaderboardRows\n",
    "#                 for row in response['leaderboardRows']:\n",
    "#                     # Extract the total number of ordinals from the scores\n",
    "#                     total_ordinals = pd.DataFrame(row['scores'] for row in response['leaderboardRows']).shape[1]\n",
    "#                     # Iterate over each ordinal\n",
    "#                     for ordinal in range(0, total_ordinals):\n",
    "#                         # Copy the entrant data and add additional fields for overallRank and overallScore\n",
    "#                         row_data = row['scores'][ordinal].copy()\n",
    "#                         row_data['competitorId'] = row['entrant']['competitorId']\n",
    "#                         # Append the row data to the data_list\n",
    "#                         data_list.append(row_data)\n",
    "#             except Exception as e:\n",
    "#                 # Handle any errors that occur during the API request for a specific page\n",
    "#                 print(f\"Error occurred while fetching data for gender={gender}, page={page}: {e}\")\n",
    "#     except Exception as e:\n",
    "#         # Handle any errors that occur during the API request for fetching total_pages\n",
    "#         print(f\"Error occurred while fetching total_pages for gender={gender}: {e}\")\n",
    "\n",
    "# # Create a DataFrame from the collected data_list\n",
    "# df = pd.DataFrame(data_list)\n",
    "\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quarterfinals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Athletes information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://c3po.crossfit.com/api/leaderboards/v2/competitions/quarterfinalsindividual/2021/leaderboards\"\n",
    "\n",
    "data_list = []\n",
    "genders = [1, 2]\n",
    "\n",
    "# Iterate over each gender\n",
    "for gender in genders:\n",
    "    # Create the initial API URL to fetch the data for the first page\n",
    "    url = f\"{base_url}?division={gender}&page=1\"\n",
    "    try:\n",
    "        # Fetch the response for the first page\n",
    "        response = requests.get(url).json()\n",
    "        # Extract the total number of pages from the response\n",
    "        total_pages = response['pagination']['totalPages']\n",
    "        # Iterate over each page\n",
    "        for page in range(1, total_pages + 1):\n",
    "            # Create the API URL for each page\n",
    "            url = f\"{base_url}?division={gender}&page={page}\"\n",
    "            try:\n",
    "                # Fetch the response for the current page\n",
    "                response = requests.get(url).json()\n",
    "                # Extract the data for each row in the leaderboardRows\n",
    "                for row in response['leaderboardRows']:\n",
    "                    # Copy the entrant data and add additional fields for overallRank and overallScore\n",
    "                    row_data = row['entrant'].copy()\n",
    "                    row_data['overallRank'] = row['overallRank']\n",
    "                    row_data['overallScore'] = row['overallScore']\n",
    "                    # Append the row data to the data_list\n",
    "                    data_list.append(row_data)\n",
    "            except Exception as e:\n",
    "                # Handle any errors that occur during the API request for a specific page\n",
    "                print(f\"Error occurred while fetching data for gender={gender}, page={page}: {e}\")\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the API request for fetching total_pages\n",
    "        print(f\"Error occurred while fetching total_pages for gender={gender}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the collected data_list\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Athletes scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://c3po.crossfit.com/api/leaderboards/v2/competitions/quarterfinalsindividual/2021/leaderboards\"\n",
    "\n",
    "data_list = []\n",
    "genders = [1, 2]\n",
    "\n",
    "# Iterate over each gender\n",
    "for gender in genders:\n",
    "    # Create the initial API URL to fetch the data for the first page\n",
    "    url = f\"{base_url}?division={gender}&page=1\"\n",
    "    try:\n",
    "        # Fetch the response for the first page\n",
    "        response = requests.get(url).json()\n",
    "        # Extract the total number of pages from the response\n",
    "        total_pages = response['pagination']['totalPages']\n",
    "        # Iterate over each page\n",
    "        for page in range(1, total_pages + 1):\n",
    "            # Create the API URL for each page\n",
    "            url = f\"{base_url}?division={gender}&page={page}\"\n",
    "            try:\n",
    "                # Fetch the response for the current page\n",
    "                response = requests.get(url).json()\n",
    "                # Extract the data for each row in the leaderboardRows\n",
    "                for row in response['leaderboardRows']:\n",
    "                    # Extract the total number of ordinals from the scores\n",
    "                    total_ordinals = pd.DataFrame(row['scores'] for row in response['leaderboardRows']).shape[1]\n",
    "                    # Iterate over each ordinal\n",
    "                    for ordinal in range(0, total_ordinals):\n",
    "                        # Copy the entrant data and add additional fields for overallRank and overallScore\n",
    "                        row_data = row['scores'][ordinal].copy()\n",
    "                        row_data['competitorId'] = row['entrant']['competitorId']\n",
    "                        # Append the row data to the data_list\n",
    "                        data_list.append(row_data)\n",
    "            except Exception as e:\n",
    "                # Handle any errors that occur during the API request for a specific page\n",
    "                print(f\"Error occurred while fetching data for gender={gender}, page={page}: {e}\")\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the API request for fetching total_pages\n",
    "        print(f\"Error occurred while fetching total_pages for gender={gender}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the collected data_list\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Semifinals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Athletes information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://c3po.crossfit.com/api/leaderboards/v2/competitions/semifinals/2021/leaderboards\"\n",
    "\n",
    "data_list = []\n",
    "semifinals = [176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187]\n",
    "genders = [1, 2]\n",
    "\n",
    "# Iterate over each semifinal\n",
    "for semifinal in semifinals:\n",
    "    # Iterate over each gender\n",
    "    for gender in genders:\n",
    "        # Create the initial API URL to fetch the data for the first page\n",
    "        url = f\"{base_url}?semifinal={semifinal}&division={gender}&page=1\"\n",
    "        try:\n",
    "            # Fetch the response for the first page\n",
    "            response = requests.get(url).json()\n",
    "            # Extract the total number of pages from the response\n",
    "            total_pages = response['pagination']['totalPages']\n",
    "            # Iterate over each page\n",
    "            for page in range(1, total_pages + 1):\n",
    "                # Create the API URL for each page\n",
    "                url = f\"{base_url}?semifinal={semifinal}&division={gender}&page={page}\"\n",
    "                try:\n",
    "                    # Fetch the response for the current page\n",
    "                    response = requests.get(url).json()\n",
    "                    # Extract the data for each row in the leaderboardRows\n",
    "                    for row in response['leaderboardRows']:\n",
    "                        # Copy the entrant data and add additional fields for overallRank and overallScore\n",
    "                        row_data = row['entrant'].copy()\n",
    "                        row_data['overallRank'] = row['overallRank']\n",
    "                        row_data['overallScore'] = row['overallScore']\n",
    "                        # Append the row data to the data_list\n",
    "                        data_list.append(row_data)\n",
    "                except Exception as e:\n",
    "                    # Handle any errors that occur during the API request for a specific page\n",
    "                    print(f\"Error occurred while fetching data for semifinal={semifinal}, gender={gender}, page={page}: {e}\")\n",
    "        except Exception as e:\n",
    "            # Handle any errors that occur during the API request for fetching total_pages\n",
    "            print(f\"Error occurred while fetching total_pages for semifinal={semifinal}, gender={gender}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the collected data_list\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Athletes scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://c3po.crossfit.com/api/leaderboards/v2/competitions/semifinals/2021/leaderboards\"\n",
    "\n",
    "data_list = []\n",
    "semifinals = [176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187]\n",
    "genders = [1, 2]\n",
    "\n",
    "# Iterate over each semifinal\n",
    "for semifinal in semifinals:\n",
    "    # Iterate over each gender\n",
    "    for gender in genders:\n",
    "        # Create the initial API URL to fetch the data for the first page\n",
    "        url = f\"{base_url}?semifinal={semifinal}&division={gender}&page=1\"\n",
    "        try:\n",
    "            # Fetch the response for the first page\n",
    "            response = requests.get(url).json()\n",
    "            # Extract the total number of pages from the response\n",
    "            total_pages = response['pagination']['totalPages']\n",
    "            # Iterate over each page\n",
    "            for page in range(1, total_pages + 1):\n",
    "                # Create the API URL for each page\n",
    "                url = f\"{base_url}?semifinal={semifinal}&division={gender}&page={page}\"\n",
    "                try:\n",
    "                    # Fetch the response for the current page\n",
    "                    response = requests.get(url).json()\n",
    "                    # Extract the data for each row in the leaderboardRows\n",
    "                    for row in response['leaderboardRows']:\n",
    "                        # Extract the total number of ordinals from the scores\n",
    "                        total_ordinals = pd.DataFrame(row['scores'] for row in response['leaderboardRows']).shape[1]\n",
    "                        # Iterate over each ordinal\n",
    "                        for ordinal in range(0, total_ordinals):\n",
    "                            # Copy the entrant data and add additional fields for overallRank and overallScore\n",
    "                            row_data = row['scores'][ordinal].copy()\n",
    "                            row_data['competitorId'] = row['entrant']['competitorId']\n",
    "                            # Append the row data to the data_list\n",
    "                            data_list.append(row_data)\n",
    "                except Exception as e:\n",
    "                    # Handle any errors that occur during the API request for a specific page\n",
    "                    print(f\"Error occurred while fetching data for semifinal={semifinal}, gender={gender}, page={page}: {e}\")\n",
    "        except Exception as e:\n",
    "            # Handle any errors that occur during the API request for fetching total_pages\n",
    "            print(f\"Error occurred while fetching total_pages for semifinal={semifinal}, gender={gender}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the collected data_list\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Games"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Athletes information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorId</th>\n",
       "      <th>competitorName</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>status</th>\n",
       "      <th>postCompStatus</th>\n",
       "      <th>gender</th>\n",
       "      <th>profilePicS3key</th>\n",
       "      <th>countryOfOriginCode</th>\n",
       "      <th>countryOfOriginName</th>\n",
       "      <th>...</th>\n",
       "      <th>regionName</th>\n",
       "      <th>divisionId</th>\n",
       "      <th>affiliateId</th>\n",
       "      <th>affiliateName</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>teamCaptain</th>\n",
       "      <th>overallRank</th>\n",
       "      <th>overallScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>811708</td>\n",
       "      <td>Justin Medeiros</td>\n",
       "      <td>Justin</td>\n",
       "      <td>Medeiros</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>672d4-P811708_4-184.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>1792</td>\n",
       "      <td>CrossFit Fort Vancouver</td>\n",
       "      <td>22</td>\n",
       "      <td>69 in</td>\n",
       "      <td>195 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158264</td>\n",
       "      <td>Patrick Vellner</td>\n",
       "      <td>Patrick</td>\n",
       "      <td>Vellner</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>d471c-P158264_7-184.jpg</td>\n",
       "      <td>CA</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>1918</td>\n",
       "      <td>CrossFit Nanaimo</td>\n",
       "      <td>31</td>\n",
       "      <td>71 in</td>\n",
       "      <td>195 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107101</td>\n",
       "      <td>Brent Fikowski</td>\n",
       "      <td>Brent</td>\n",
       "      <td>Fikowski</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>93ab7-P107101_10-184.jpg</td>\n",
       "      <td>CA</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>30</td>\n",
       "      <td>74 in</td>\n",
       "      <td>220 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81616</td>\n",
       "      <td>Björgvin Karl Guðmundsson</td>\n",
       "      <td>Björgvin Karl</td>\n",
       "      <td>Guðmundsson</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>4c5dc-P81616_4-184.jpg</td>\n",
       "      <td>IS</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>...</td>\n",
       "      <td>Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>4860</td>\n",
       "      <td>CrossFit Hengill</td>\n",
       "      <td>28</td>\n",
       "      <td>178 cm</td>\n",
       "      <td>190 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>310970</td>\n",
       "      <td>Saxon Panchik</td>\n",
       "      <td>Saxon</td>\n",
       "      <td>Panchik</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "      <td>00087-P310970_11-184.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>1</td>\n",
       "      <td>22505</td>\n",
       "      <td>CrossFit Cliffside</td>\n",
       "      <td>25</td>\n",
       "      <td>69 in</td>\n",
       "      <td>180 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2942</td>\n",
       "      <td>Kara Saunders</td>\n",
       "      <td>Kara</td>\n",
       "      <td>Saunders</td>\n",
       "      <td>WD</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>5ca2a-P2942_14-184.jpg</td>\n",
       "      <td>AU</td>\n",
       "      <td>Australia</td>\n",
       "      <td>...</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>2</td>\n",
       "      <td>9043</td>\n",
       "      <td>CrossFit Carv</td>\n",
       "      <td>31</td>\n",
       "      <td>162 cm</td>\n",
       "      <td>162 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>305891</td>\n",
       "      <td>Kari Pearce</td>\n",
       "      <td>Kari</td>\n",
       "      <td>Pearce</td>\n",
       "      <td>WD</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>17c8c-P305891_3-184.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>2</td>\n",
       "      <td>7589</td>\n",
       "      <td>CrossFit Culmination</td>\n",
       "      <td>32</td>\n",
       "      <td>63 in</td>\n",
       "      <td>139 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>455677</td>\n",
       "      <td>Larissa Cunha</td>\n",
       "      <td>Larissa</td>\n",
       "      <td>Cunha</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>d65e1-P455677_3-184.jpg</td>\n",
       "      <td>BR</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>...</td>\n",
       "      <td>South America</td>\n",
       "      <td>2</td>\n",
       "      <td>10585</td>\n",
       "      <td>Cavaleiros CrossFit</td>\n",
       "      <td>30</td>\n",
       "      <td>153 cm</td>\n",
       "      <td>62 kg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>592472</td>\n",
       "      <td>Bethany Shadburne</td>\n",
       "      <td>Bethany</td>\n",
       "      <td>Shadburne</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>69340-P592472_6-184.jpg</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>North America</td>\n",
       "      <td>2</td>\n",
       "      <td>7589</td>\n",
       "      <td>CrossFit Culmination</td>\n",
       "      <td>27</td>\n",
       "      <td>64 in</td>\n",
       "      <td>144 lb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1019212</td>\n",
       "      <td>Svetlana Kubyshkina</td>\n",
       "      <td>Svetlana</td>\n",
       "      <td>Kubyshkina</td>\n",
       "      <td>ACT</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>c584b-P1019212_1-184.jpg</td>\n",
       "      <td>RU</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>2</td>\n",
       "      <td>17189</td>\n",
       "      <td>Backstage CrossFit</td>\n",
       "      <td>30</td>\n",
       "      <td>155 cm</td>\n",
       "      <td>60 kg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   competitorId             competitorName      firstName     lastName status  \\\n",
       "0        811708            Justin Medeiros         Justin     Medeiros    ACT   \n",
       "1        158264            Patrick Vellner        Patrick      Vellner    ACT   \n",
       "2        107101             Brent Fikowski          Brent     Fikowski    ACT   \n",
       "3         81616  Björgvin Karl Guðmundsson  Björgvin Karl  Guðmundsson    ACT   \n",
       "4        310970              Saxon Panchik          Saxon      Panchik    ACT   \n",
       "..          ...                        ...            ...          ...    ...   \n",
       "75         2942              Kara Saunders           Kara     Saunders     WD   \n",
       "76       305891                Kari Pearce           Kari       Pearce     WD   \n",
       "77       455677              Larissa Cunha        Larissa        Cunha    ACT   \n",
       "78       592472          Bethany Shadburne        Bethany    Shadburne    ACT   \n",
       "79      1019212        Svetlana Kubyshkina       Svetlana   Kubyshkina    ACT   \n",
       "\n",
       "   postCompStatus gender           profilePicS3key countryOfOriginCode  \\\n",
       "0                      M   672d4-P811708_4-184.jpg                  US   \n",
       "1                      M   d471c-P158264_7-184.jpg                  CA   \n",
       "2                      M  93ab7-P107101_10-184.jpg                  CA   \n",
       "3                      M    4c5dc-P81616_4-184.jpg                  IS   \n",
       "4                      M  00087-P310970_11-184.jpg                  US   \n",
       "..            ...    ...                       ...                 ...   \n",
       "75                     F    5ca2a-P2942_14-184.jpg                  AU   \n",
       "76                     F   17c8c-P305891_3-184.jpg                  US   \n",
       "77                     F   d65e1-P455677_3-184.jpg                  BR   \n",
       "78                     F   69340-P592472_6-184.jpg                  US   \n",
       "79                     F  c584b-P1019212_1-184.jpg                  RU   \n",
       "\n",
       "   countryOfOriginName  ...     regionName divisionId affiliateId  \\\n",
       "0        United States  ...  North America          1        1792   \n",
       "1               Canada  ...  North America          1        1918   \n",
       "2               Canada  ...  North America          1        None   \n",
       "3              Iceland  ...         Europe          1        4860   \n",
       "4        United States  ...  North America          1       22505   \n",
       "..                 ...  ...            ...        ...         ...   \n",
       "75           Australia  ...        Oceania          2        9043   \n",
       "76       United States  ...  North America          2        7589   \n",
       "77              Brazil  ...  South America          2       10585   \n",
       "78       United States  ...  North America          2        7589   \n",
       "79                      ...           Asia          2       17189   \n",
       "\n",
       "              affiliateName age  height  weight teamCaptain overallRank  \\\n",
       "0   CrossFit Fort Vancouver  22   69 in  195 lb           0           1   \n",
       "1          CrossFit Nanaimo  31   71 in  195 lb           0           2   \n",
       "2                            30   74 in  220 lb           0           3   \n",
       "3          CrossFit Hengill  28  178 cm  190 lb           0           4   \n",
       "4        CrossFit Cliffside  25   69 in  180 lb           0           5   \n",
       "..                      ...  ..     ...     ...         ...         ...   \n",
       "75            CrossFit Carv  31  162 cm  162 lb           0          36   \n",
       "76     CrossFit Culmination  32   63 in  139 lb           0          37   \n",
       "77      Cavaleiros CrossFit  30  153 cm   62 kg           0           0   \n",
       "78     CrossFit Culmination  27   64 in  144 lb           0           0   \n",
       "79       Backstage CrossFit  30  155 cm   60 kg           0           0   \n",
       "\n",
       "   overallScore  \n",
       "0          1234  \n",
       "1          1152  \n",
       "2          1028  \n",
       "3          1004  \n",
       "4           996  \n",
       "..          ...  \n",
       "75           93  \n",
       "76            0  \n",
       "77            0  \n",
       "78            0  \n",
       "79            0  \n",
       "\n",
       "[80 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query 7 - 2021 Games Not Scores\n",
    "df_2021_games_not_scores = scraping_data_open_and_games('2021', 'games')\n",
    "\n",
    "df_2021_games_not_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Athletes scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ordinal</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>valid</th>\n",
       "      <th>scoreDisplay</th>\n",
       "      <th>scoreIdentifier</th>\n",
       "      <th>mobileScoreDisplay</th>\n",
       "      <th>scaled</th>\n",
       "      <th>video</th>\n",
       "      <th>heat</th>\n",
       "      <th>lane</th>\n",
       "      <th>breakdown</th>\n",
       "      <th>competitorId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>1:10:54.31</td>\n",
       "      <td>7c1a5d8597b52e58b888</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>88 pts</td>\n",
       "      <td>811708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>09:13.54</td>\n",
       "      <td>17abd90e392bf5f82867</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>58 pts</td>\n",
       "      <td>811708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>01:18.21</td>\n",
       "      <td>e36bf0a693c297204fc2</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>70 pts</td>\n",
       "      <td>811708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>14:50.28</td>\n",
       "      <td>2909e36dc32303d62419</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>97 pts</td>\n",
       "      <td>811708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>12:05.77</td>\n",
       "      <td>42fa841b175f953cd3fe</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>91 pts</td>\n",
       "      <td>811708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ordinal rank score valid scoreDisplay       scoreIdentifier  \\\n",
       "0           1    5    88     1   1:10:54.31  7c1a5d8597b52e58b888   \n",
       "1           2   15    58     1     09:13.54  17abd90e392bf5f82867   \n",
       "2           3   11    70     1     01:18.21  e36bf0a693c297204fc2   \n",
       "3           4    2    97     1     14:50.28  2909e36dc32303d62419   \n",
       "4           5    4    91     1     12:05.77  42fa841b175f953cd3fe   \n",
       "...       ...  ...   ...   ...          ...                   ...   \n",
       "1195       11         -1                                     None   \n",
       "1196       12         -1                                     None   \n",
       "1197       13         -1                                     None   \n",
       "1198       14         -1                                     None   \n",
       "1199       15         -1                                     None   \n",
       "\n",
       "     mobileScoreDisplay scaled video heat lane breakdown competitorId  \n",
       "0                            0     0              88 pts       811708  \n",
       "1                            0     0              58 pts       811708  \n",
       "2                            0     0              70 pts       811708  \n",
       "3                            0     0              97 pts       811708  \n",
       "4                            0     0              91 pts       811708  \n",
       "...                 ...    ...   ...  ...  ...       ...          ...  \n",
       "1195                         0     0                 NaN      1019212  \n",
       "1196                         0     0                 NaN      1019212  \n",
       "1197                         0     0                 NaN      1019212  \n",
       "1198                         0     0                 NaN      1019212  \n",
       "1199                         0     0                 NaN      1019212  \n",
       "\n",
       "[1200 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query 8 - 2021 Games Scores\n",
    "df_2021_games_scores = scraping_data_open_and_games('2021', 'games', scores=True)\n",
    "\n",
    "df_2021_games_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
